{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async replication\n",
    "\n",
    "https://github.com/popkir/highload-social-network/commit/f071c6c8ba88a87300afb193d0174f1e204b4191"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как создать две асинхронные реплики"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. В docker-compose.yml замапил папки с данными в контейнер с базой данных:\n",
    "   ```\n",
    "   services:\n",
    "     db_0:\n",
    "       volumes:\n",
    "       - ./postgres_data/db_0:/var/lib/postgresql/data\n",
    "   ```\n",
    "\n",
    "2. Запустил бэкенд и базу, накатил миграции (включая создание роли для репликации):\n",
    "   ```\n",
    "   docker-compose exec -it backend alembic revision head\n",
    "   ```\n",
    "   В папке `./postgres_data/db_0` появилось много интересных файлов.\n",
    "\n",
    "3. Скопировал полученный на предыдущем шаге шаблон конфиг файла `./postgres_data/db_0/postgres.conf` в `./postgres_config/postgresql.db0.conf`. \n",
    "   \n",
    "   Добавил следующие строки:\n",
    "   ```\n",
    "   ssl = off\n",
    "   wal_level = replica\n",
    "   max_wal_senders = 4 # expected slave number\n",
    "   ```\n",
    "\n",
    "4. Посмотрел маску подсети через `docker network inspect social-network-default | grep Subnet`: 172.18.0.0/16. \n",
    "\n",
    "   Скопировал полученный на предыдущем шаге шаблон конфиг файла `./postgres_data/db_0/pg_hba.conf` в `./postgres_config/pg_hba.conf`.\n",
    "\n",
    "   Добавил следующую строку: ```host    replication     replicator      172.18.0.0/16           scram-sha-256```\n",
    "\n",
    "5. Добавил мэппинг конфигурационных файлов в контейнер:\n",
    "   ```\n",
    "   services:\n",
    "     db_0:\n",
    "       volumes:\n",
    "       - ./postgres_data/db_0:/var/lib/postgresql/data\n",
    "       - ./postgres_config/postgresql.db0.conf:/var/lib/postgresql/data/postgresql.conf\n",
    "       - ./postgres_config/pg_hba.conf:/var/lib/postgresql/data/pg_hba.conf\n",
    "   ```\n",
    "\n",
    "6. Запустил сервисы. Сделал бэкап для реплик:\n",
    "   ```\n",
    "   docker exec -it social-network-db_0 bash\n",
    "   mkdir /pgslave\n",
    "   pg_basebackup -h social-network-db_0 -D /pgslave -U replicator -v -P --wal-method=stream\n",
    "   exit\n",
    "   ```\n",
    "\n",
    "7. Создал две пустые папки: `./postgres_data/db_1` и `./postgres_data/db_2`.\n",
    "   \n",
    "   Скопировал в них бэкап первой базы данных:\n",
    "   ```\n",
    "   docker cp social-network-db_0:/pgslave postgres_data/db_1\n",
    "   docker cp social-network-db_0:/pgslave postgres_data/db_2\n",
    "   ```\n",
    "\n",
    "8. Создал два контейнера в `docker-compose.yml`:\n",
    "   ```\n",
    "   db_1:\n",
    "    image: postgres:15\n",
    "    container_name: social-network-db_1\n",
    "    volumes:\n",
    "      - ./postgres_data/db_1:/var/lib/postgresql/data\n",
    "    networks:\n",
    "      - social-network-default\n",
    "    ports:\n",
    "      - \"15432:5432\"\n",
    "    ```\n",
    "    ```\n",
    "    db_2:\n",
    "      image: postgres:15\n",
    "      container_name: social-network-db_2\n",
    "      volumes:\n",
    "        - ./postgres_data/db_2:/var/lib/postgresql/data\n",
    "      networks:\n",
    "        - social-network-default\n",
    "      ports:\n",
    "        - \"25432:5432\"\n",
    "    ```\n",
    "\n",
    "9. Запустил сервисы и проверил, что все работает.\n",
    "\n",
    "10. Создал версию конфиг файла для реплик, сделав `cp postgres_config/postgresql.db0.conf postgres_config/postgresql.db1.conf` и добавив туда строку `primary_conninfo = 'host=social-network-db_0 port=5432 user=replicator password=replicator application_name=pgslave_db_1'`.\n",
    "    \n",
    "    Аналогично создал файл `postgres_config/postgresql.db2.conf` с параметром `application_name=pgslave_db_2`.\n",
    "\n",
    "11. Создал пустой файл `postgres_config/standby.signal`.\n",
    "\n",
    "12. Удалил файлы `postgres.conf` и `pg_hba.conf` из папок `postgres_data/db_0`, `postgres_data/db_1`, `postgres_data/db_2`.\n",
    "\n",
    "13. Добавил мэппинги конфигурационных файлов в `docker-compose.yml`:\n",
    "  ```\n",
    "  db_1:\n",
    "    volumes:\n",
    "      - ./postgres_data/db_1:/var/lib/postgresql/data\n",
    "      - ./postgres_config/postgresql.db1.conf:/var/lib/postgresql/data/postgresql.conf\n",
    "      - ./postgres_config/pg_hba.conf:/var/lib/postgresql/data/pg_hba.conf\n",
    "      - ./postgres_config/standby.signal:/var/lib/postgresql/data/standby.signal\n",
    "  \n",
    "  db_2:\n",
    "    volumes:\n",
    "      - ./postgres_data/db_2:/var/lib/postgresql/data\n",
    "      - ./postgres_config/postgresql.db2.conf:/var/lib/postgresql/data/postgresql.conf\n",
    "      - ./postgres_config/pg_hba.conf:/var/lib/postgresql/data/pg_hba.conf\n",
    "      - ./postgres_config/standby.signal:/var/lib/postgresql/data/standby.signal\n",
    "  ```\n",
    "\n",
    "14. Перезапустил сервисы. Проверил по логам, что все успешно настроено.\n",
    "\n",
    "15. Проверил еще раз, создав сессию к базе `db_0` (мастер) и выполнив запрос `select application_name, sync_state from pg_stat_replication;`, убедившись, что две реплики подключились в асинхронном режиме\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как перевести запросы на реплики\n",
    "\n",
    "Я поменял файлы окружения и импорт из них в проекте, так, чтобы теперь все 3 ссылки были доступны.\n",
    "\n",
    "Создал фабрики сессий ко всем трем серверам.\n",
    "\n",
    "Вместо использования scoped_session напрямую, создал вспомогательный класс:\n",
    "```\n",
    "class SessionManager:\n",
    "    master_session = scoped_session(master_session_factory)\n",
    "    slave_sessions = [scoped_session(s) for s in slave_session_factories]\n",
    "    current = master_session\n",
    "```\n",
    "\n",
    "Перевел уже имеющиеся запросы на использование `SessionManager.current`.\n",
    "\n",
    "Создал фабрику декораторов, подменяющих сессии в скоупе функции, завернутой в декоратор, на выбранный или случайный слейв, а затем заменяющих их обратно:\n",
    "```\n",
    "def with_slave(which_slave=None):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        async def wrapper(*args, **kwargs):\n",
    "            if which_slave is not None:\n",
    "                SessionManager.current = SessionManager.slave_sessions[which_slave]\n",
    "            else:\n",
    "                SessionManager.current = random.choice(SessionManager.slave_sessions)\n",
    "            res = await func(*args, **kwargs)\n",
    "            SessionManager.current = SessionManager.master_session\n",
    "            return res\n",
    "        return wrapper\n",
    "    return decorator\n",
    "```\n",
    "\n",
    "Эндпоинты, которые хочу перевести на слейв, завернул в этот декоратор:\n",
    "```\n",
    "@router.get(\"/search\", response_model=dict)\n",
    "@with_slave()\n",
    "@close_session\n",
    "async def search_user(first_name: str = None, last_name: str = None):   \n",
    "    ...\n",
    "```\n",
    "\n",
    "Для проверки, что подмена сессий происходит корректно, провел нагрузочный тест, в котором одновременно подавалась нагрузка на эндпоинты, перведенные на реплики, и на эндпоинты, производящие запись в базу. Ошибок не было.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нагрузочный тест - до и после подключения реплик"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Протокол\n",
    "\n",
    "Нагрузочный тест проведен с помощью фреймворка Locust. \n",
    "\n",
    "Нагрузка была распределена поровну между `user/get/{id}` и `user/search`.\n",
    "\n",
    "После подключения реплик, оба этих запроса были переведены на реплики для чтения. Был использован случайный выбор реплики при обработке каждого запроса.\n",
    "\n",
    "В качестве профиля нагрузки я использовал следующие параметры:\n",
    "- 3 минуты с 1 одновременным пользователем, скорость появления новых пользователей 1 пользователь/с\n",
    "- 3 минуты с 10 одновременными пользователями, скорость появления новых пользователей 10 пользователей/с\n",
    "- 3 минуты с 100 одновременными пользователями, скорость появления новых пользователей 100 пользователей/с\n",
    "- 3 минуты с 1000 одновременными пользователями, скорость появления новых пользователей 1000 пользователей/с\n",
    "\n",
    "Замерялись следующие характеристики:\n",
    "- использование процессора, памяти и диска (через docker stats)\n",
    "- latency (50%, 95%) и throughput запросов с нагружающей стороны (через locust). \n",
    "\n",
    "(Мы попробовали мерять latency запросов в базе через postgres-exporter + prometheus + grafana, но не достигли понятно интерпретируемого результата)\n",
    "\n",
    "Первые 60 секунд каждой из фаз нагрузки были исключены из анализа."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СPU\n",
    "\n",
    "Без реплик\n",
    "![image info](./001_load_test_search_get_without_replica/result_plots/container_cpu_usage.png)\n",
    "\n",
    "С использованием реплик\n",
    "![image info](./002_load_test_search_get_from_async_slave/result_plots/container_cpu_usage.png)\n",
    "\n",
    "Очевидно, при переводе запросов на реплики, мастер потребляет меньше ресурсов процессора.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAM\n",
    "\n",
    "Без реплик\n",
    "![image info](./001_load_test_search_get_without_replica/result_plots/container_memory_usage.png)\n",
    "\n",
    "С использованием реплик\n",
    "![image info](./002_load_test_search_get_from_async_slave/result_plots/container_memory_usage.png)\n",
    "\n",
    "При переводе запросов на реплики, мастер потребляет меньше ресурсов памяти.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disk Reads\n",
    "\n",
    "Без реплик\n",
    "![image info](./001_load_test_search_get_without_replica/result_plots/container_disk_read.png)\n",
    "\n",
    "С использованием реплик\n",
    "![image info](./002_load_test_search_get_from_async_slave/result_plots/container_disk_read.png)\n",
    "\n",
    "При переводе запросов на реплики, мастер потребляет меньше ресурсов диска.\n",
    "\n",
    "Почему одна из реплик якобы потребляет еще меньше? Не знаю, не хочу повторять эксперимент. Нагрузка между репликами точно была расределена поровну, возможно, баг сбора телеметрии.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики со стороны клиента"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughput\n",
    "![image info](./002_load_test_search_get_from_async_slave/result_plots/client_contrast_throughput.png)\n",
    "\n",
    "Latency 50%\n",
    "![image info](./002_load_test_search_get_from_async_slave/result_plots/client_contrast_latency_50.png)\n",
    "\n",
    "Latency 95%\n",
    "![image info](./002_load_test_search_get_from_async_slave/result_plots/client_contrast_latency_95.png)\n",
    "\n",
    "Можно заметить, что подключение реплик:\n",
    "- незначительно уменьшает throughput\n",
    "- чуть более значительно увеличивает latency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quorum sync replication\n",
    "\n",
    "https://github.com/popkir/highload-social-network/commit/badcb4067e476951fe1715d99fcd33e83112d74c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как было сделано\n",
    "\n",
    "1. В файл `postgres_config/postgresql.db0.conf` добавлены следующие строки:\n",
    "   ```\n",
    "    synchronous_commit = on\n",
    "    synchronous_standby_names = 'ANY 1 (pgslave_db_1, pgslave_db_2)'\n",
    "   ```\n",
    "\n",
    "2. Сервисы перезапущены, проверил в логах и в `pg_stat_replication`, что настройка применена успешно.\n",
    "\n",
    "3. Подаем нагрузку на запись в таблицу `template` через эндпоинт `template/generate`. Записываем 30000 записей.\n",
    "\n",
    "4. После ~12000 записей, останавливаем сервер `db2`: `docker stop social-network-db_2`\n",
    "\n",
    "5. Ждем завершения обработки запроса. Видим логи об успешной записи 30000 строк:\n",
    "![logs](sync-quorum-logs.png)\n",
    "\n",
    "6. Останавливаем все базы, запускаем их по одной и проверяем число записей в таблице `template`:\n",
    "   \n",
    "![db0](sync-quorum-db0.png)\n",
    "![db1](sync-quorum-db1.png)\n",
    "![db2-before](sync-quorum-db2-before.png)\n",
    "\n",
    "1. Удаляем строки из пункта 1 из `postgres_config/postgresql.db0.conf`. \n",
    "   Добавляем `primary_conninfo = 'host=social-network-db_1 port=5432 user=replicator password=replicator application_name=pgslave_db_0'`\n",
    "\n",
    "2. Вносим в `postgres_config/postgresql.db1.conf`:\n",
    "   ```\n",
    "   synchronous_commit = on\n",
    "   synchronous_standby_names = 'ANY 1 (pgslave_db_0, pgslave_db_2)'\n",
    "   ```\n",
    "3. Редактируем `docker-compose.yml` - удаляем мэппинг `standby.signal` из `db_1` и добавляем в `db_0`.\n",
    "\n",
    "4.  Проверяем, что в папках `postgres_data/db_{NUMBER}` нет файлов `postgresql.conf`, `pg_hba.conf`, `standby.signal`. Если есть, удаляем.\n",
    "\n",
    "5.  Перезапускаем все сервисы. Проверяем, что `db_1` стал мастером:\n",
    "   \n",
    "   ![db1-master](./sync-quorum-db1-master.png)\n",
    "\n",
    "6.  Проверяем, что `db_2` получил все потерянные записи:\n",
    "    \n",
    "   ![db2-after](./sync-quorum-db2-after.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
